{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b29868",
   "metadata": {},
   "source": [
    "Car Price Prediction - ML Project\n",
    "A comprehensive analysis for predicting car prices in the American market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f83f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80bfcf2",
   "metadata": {},
   "source": [
    "1. Loading and Preprocessing\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7759f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('CarPrice_Assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d59d5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Shape: (205, 26)\n",
      "\n",
      "First few rows:\n",
      "   car_ID  symboling                   CarName fueltype aspiration doornumber  \\\n",
      "0       1          3        alfa-romero giulia      gas        std        two   \n",
      "1       2          3       alfa-romero stelvio      gas        std        two   \n",
      "2       3          1  alfa-romero Quadrifoglio      gas        std        two   \n",
      "3       4          2               audi 100 ls      gas        std       four   \n",
      "4       5          2                audi 100ls      gas        std       four   \n",
      "\n",
      "       carbody drivewheel enginelocation  wheelbase  ...  enginesize  \\\n",
      "0  convertible        rwd          front       88.6  ...         130   \n",
      "1  convertible        rwd          front       88.6  ...         130   \n",
      "2    hatchback        rwd          front       94.5  ...         152   \n",
      "3        sedan        fwd          front       99.8  ...         109   \n",
      "4        sedan        4wd          front       99.4  ...         136   \n",
      "\n",
      "   fuelsystem  boreratio  stroke compressionratio horsepower  peakrpm citympg  \\\n",
      "0        mpfi       3.47    2.68              9.0        111     5000      21   \n",
      "1        mpfi       3.47    2.68              9.0        111     5000      21   \n",
      "2        mpfi       2.68    3.47              9.0        154     5000      19   \n",
      "3        mpfi       3.19    3.40             10.0        102     5500      24   \n",
      "4        mpfi       3.19    3.40              8.0        115     5500      18   \n",
      "\n",
      "   highwaympg    price  \n",
      "0          27  13495.0  \n",
      "1          27  16500.0  \n",
      "2          26  16500.0  \n",
      "3          30  13950.0  \n",
      "4          22  17450.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5aa115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "car_ID              0\n",
      "symboling           0\n",
      "CarName             0\n",
      "fueltype            0\n",
      "aspiration          0\n",
      "doornumber          0\n",
      "carbody             0\n",
      "drivewheel          0\n",
      "enginelocation      0\n",
      "wheelbase           0\n",
      "carlength           0\n",
      "carwidth            0\n",
      "carheight           0\n",
      "curbweight          0\n",
      "enginetype          0\n",
      "cylindernumber      0\n",
      "enginesize          0\n",
      "fuelsystem          0\n",
      "boreratio           0\n",
      "stroke              0\n",
      "compressionratio    0\n",
      "horsepower          0\n",
      "peakrpm             0\n",
      "citympg             0\n",
      "highwaympg          0\n",
      "price               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c001fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "car_ID                int64\n",
      "symboling             int64\n",
      "CarName              object\n",
      "fueltype             object\n",
      "aspiration           object\n",
      "doornumber           object\n",
      "carbody              object\n",
      "drivewheel           object\n",
      "enginelocation       object\n",
      "wheelbase           float64\n",
      "carlength           float64\n",
      "carwidth            float64\n",
      "carheight           float64\n",
      "curbweight            int64\n",
      "enginetype           object\n",
      "cylindernumber       object\n",
      "enginesize            int64\n",
      "fuelsystem           object\n",
      "boreratio           float64\n",
      "stroke              float64\n",
      "compressionratio    float64\n",
      "horsepower            int64\n",
      "peakrpm               int64\n",
      "citympg               int64\n",
      "highwaympg            int64\n",
      "price               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7b5ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Summary:\n",
      "           car_ID   symboling   wheelbase   carlength    carwidth   carheight  \\\n",
      "count  205.000000  205.000000  205.000000  205.000000  205.000000  205.000000   \n",
      "mean   103.000000    0.834146   98.756585  174.049268   65.907805   53.724878   \n",
      "std     59.322565    1.245307    6.021776   12.337289    2.145204    2.443522   \n",
      "min      1.000000   -2.000000   86.600000  141.100000   60.300000   47.800000   \n",
      "25%     52.000000    0.000000   94.500000  166.300000   64.100000   52.000000   \n",
      "50%    103.000000    1.000000   97.000000  173.200000   65.500000   54.100000   \n",
      "75%    154.000000    2.000000  102.400000  183.100000   66.900000   55.500000   \n",
      "max    205.000000    3.000000  120.900000  208.100000   72.300000   59.800000   \n",
      "\n",
      "        curbweight  enginesize   boreratio      stroke  compressionratio  \\\n",
      "count   205.000000  205.000000  205.000000  205.000000        205.000000   \n",
      "mean   2555.565854  126.907317    3.329756    3.255415         10.142537   \n",
      "std     520.680204   41.642693    0.270844    0.313597          3.972040   \n",
      "min    1488.000000   61.000000    2.540000    2.070000          7.000000   \n",
      "25%    2145.000000   97.000000    3.150000    3.110000          8.600000   \n",
      "50%    2414.000000  120.000000    3.310000    3.290000          9.000000   \n",
      "75%    2935.000000  141.000000    3.580000    3.410000          9.400000   \n",
      "max    4066.000000  326.000000    3.940000    4.170000         23.000000   \n",
      "\n",
      "       horsepower      peakrpm     citympg  highwaympg         price  \n",
      "count  205.000000   205.000000  205.000000  205.000000    205.000000  \n",
      "mean   104.117073  5125.121951   25.219512   30.751220  13276.710571  \n",
      "std     39.544167   476.985643    6.542142    6.886443   7988.852332  \n",
      "min     48.000000  4150.000000   13.000000   16.000000   5118.000000  \n",
      "25%     70.000000  4800.000000   19.000000   25.000000   7788.000000  \n",
      "50%     95.000000  5200.000000   24.000000   30.000000  10295.000000  \n",
      "75%    116.000000  5500.000000   30.000000   34.000000  16503.000000  \n",
      "max    288.000000  6600.000000   49.000000   54.000000  45400.000000  \n"
     ]
    }
   ],
   "source": [
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b167a",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6cdad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the car_ID column as it's just an identifier\n",
    "df = df.drop('car_ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a19bed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical\n",
    "categorical_features = ['CarName', 'fueltype', 'aspiration', 'doornumber', \n",
    "                        'carbody', 'drivewheel', 'enginelocation', \n",
    "                        'enginetype', 'cylindernumber', 'fuelsystem']\n",
    "numerical_features = [col for col in df.columns if col not in categorical_features and col != 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "787355d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract car manufacturer from CarName\n",
    "df['manufacturer'] = df['CarName'].apply(lambda x: x.split(' ')[0])\n",
    "df = df.drop('CarName', axis=1)\n",
    "categorical_features.remove('CarName')\n",
    "categorical_features.append('manufacturer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7cc3a",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e999cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix for numerical features\n",
    "plt.figure(figsize=(15, 10))\n",
    "correlation = df[numerical_features + ['price']].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dea4214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable (price)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['price'], kde=True)\n",
    "plt.title('Distribution of Car Prices')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('price_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66671b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature vs Target Visualization (Top correlated features)\n",
    "top_corr_features = correlation['price'].sort_values(ascending=False).drop('price').head(5).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3af2cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(top_corr_features, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.scatter(df[feature], df['price'])\n",
    "    plt.title(f'{feature} vs Price')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Price')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_features_vs_price.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae4cfaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features analysis\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, feature in enumerate(categorical_features[:6], 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(x=feature, y='price', data=df)\n",
    "    plt.title(f'{feature} vs Price')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_vs_price_1.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a74b1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "for i, feature in enumerate(categorical_features[6:], 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.boxplot(x=feature, y='price', data=df)\n",
    "    plt.title(f'{feature} vs Price')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('categorical_vs_price_2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ae88c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for modeling\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74833909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipelines\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6db4a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19859035",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11e7ec42",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c952ba7",
   "metadata": {},
   "source": [
    "2. Model Implementation\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82876287",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return r2, mse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67f4186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model performances\n",
    "model_performances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47b93315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_r2, lr_mse, lr_mae = evaluate_model(lr_pipeline, X_test, y_test)\n",
    "model_performances['Linear Regression'] = {\n",
    "    'R2': lr_r2,\n",
    "    'MSE': lr_mse,\n",
    "    'MAE': lr_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d34a8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regressor\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "dt_r2, dt_mse, dt_mae = evaluate_model(dt_pipeline, X_test, y_test)\n",
    "model_performances['Decision Tree'] = {\n",
    "    'R2': dt_r2,\n",
    "    'MSE': dt_mse,\n",
    "    'MAE': dt_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d5f7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_r2, rf_mse, rf_mae = evaluate_model(rf_pipeline, X_test, y_test)\n",
    "model_performances['Random Forest'] = {\n",
    "    'R2': rf_r2,\n",
    "    'MSE': rf_mse,\n",
    "    'MAE': rf_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42a1e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Regressor\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "gb_r2, gb_mse, gb_mae = evaluate_model(gb_pipeline, X_test, y_test)\n",
    "model_performances['Gradient Boosting'] = {\n",
    "    'R2': gb_r2,\n",
    "    'MSE': gb_mse,\n",
    "    'MAE': gb_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae2fa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Regressor\n",
    "svr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "svr_pipeline.fit(X_train, y_train)\n",
    "svr_r2, svr_mse, svr_mae = evaluate_model(svr_pipeline, X_test, y_test)\n",
    "model_performances['SVR'] = {\n",
    "    'R2': svr_r2,\n",
    "    'MSE': svr_mse,\n",
    "    'MAE': svr_mae\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032ece9",
   "metadata": {},
   "source": [
    "3. Model Evaluation\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c524fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for model comparison\n",
    "model_comparison = pd.DataFrame(model_performances).T\n",
    "model_comparison = model_comparison.sort_values('R2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8349a58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison:\n",
      "                             R2           MSE           MAE\n",
      "Random Forest      9.576212e-01  3.345553e+06  1.302010e+03\n",
      "Gradient Boosting  9.267908e-01  5.779426e+06  1.695765e+03\n",
      "Decision Tree      8.962240e-01  8.192494e+06  1.923679e+03\n",
      "SVR               -9.978948e-02  8.682180e+07  5.695278e+03\n",
      "Linear Regression -6.732595e+20  5.314981e+28  4.647172e+13\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(model_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15d4a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performances\n",
    "plt.figure(figsize=(12, 6))\n",
    "model_comparison['R2'].plot(kind='bar', color='skyblue')\n",
    "plt.title('R-squared Scores by Model')\n",
    "plt.ylabel('R-squared')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('r2_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fd631e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "model_comparison['MSE'].plot(kind='bar', color='salmon')\n",
    "plt.title('Mean Squared Error by Model')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mse_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "551951bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "model_comparison['MAE'].plot(kind='bar', color='lightgreen')\n",
    "plt.title('Mean Absolute Error by Model')\n",
    "plt.ylabel('MAE')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('mae_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07e3875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best performing model: Random Forest\n",
      "R-squared: 0.9576\n",
      "MSE: 3345553.2007\n",
      "MAE: 1302.0097\n"
     ]
    }
   ],
   "source": [
    "# Determine the best model\n",
    "best_model = model_comparison.index[0]\n",
    "print(f\"\\nBest performing model: {best_model}\")\n",
    "print(f\"R-squared: {model_comparison.loc[best_model, 'R2']:.4f}\")\n",
    "print(f\"MSE: {model_comparison.loc[best_model, 'MSE']:.4f}\")\n",
    "print(f\"MAE: {model_comparison.loc[best_model, 'MAE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b62f2",
   "metadata": {},
   "source": [
    "4. Feature Importance Analysis\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3091cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Random Forest':\n",
    "    model = rf_pipeline\n",
    "elif best_model == 'Gradient Boosting':\n",
    "    model = gb_pipeline\n",
    "elif best_model == 'Decision Tree':\n",
    "    model = dt_pipeline\n",
    "else:\n",
    "    # If Linear Regression or SVR wins, use Random Forest for feature importance\n",
    "    print(\"\\nUsing Random Forest for feature importance analysis...\")\n",
    "    model = rf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a84a1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing\n",
    "preprocessed_features = []\n",
    "for name, transformer, features in preprocessor.transformers_:\n",
    "    if name == 'num':\n",
    "        preprocessed_features.extend(features)\n",
    "    else:  # categorical features\n",
    "        # For categorical features, get the one-hot encoded feature names\n",
    "        preprocessed_features.extend([f\"{feat}_{cat}\" for feat in features \n",
    "                                     for cat in transformer.named_steps['onehot'].categories_[features.index(feat)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39381a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Important Features:\n",
      "             Feature  Importance\n",
      "6         enginesize    0.547857\n",
      "5         curbweight    0.295958\n",
      "13        highwaympg    0.045167\n",
      "10        horsepower    0.032016\n",
      "3           carwidth    0.013500\n",
      "54  manufacturer_bmw    0.007762\n",
      "2          carlength    0.007194\n",
      "1          wheelbase    0.006675\n",
      "12           citympg    0.005862\n",
      "11           peakrpm    0.005572\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances (works for tree-based models)\n",
    "if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "    feature_importances = model.named_steps['regressor'].feature_importances_\n",
    "    \n",
    "    # Create a DataFrame for feature importances\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': preprocessed_features,\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    \n",
    "    # Sort by importance\n",
    "    fi_df = fi_df.sort_values('Importance', ascending=False).head(15)\n",
    "    \n",
    "    # Visualize feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=fi_df)\n",
    "    plt.title(f'Top 15 Feature Importances ({best_model})')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importances.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nTop 10 Important Features:\")\n",
    "    print(fi_df.head(10))\n",
    "else:\n",
    "    print(\"\\nThe best model doesn't support direct feature importance calculation.\")\n",
    "    # Alternative: Use permutation importance or SHAP values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ba4331",
   "metadata": {},
   "source": [
    "5. Hyperparameter Tuning\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ae94b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing hyperparameter tuning on the best model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPerforming hyperparameter tuning on the best model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3f26f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    best_pipeline = rf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3e8bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'regressor__max_depth': [3, 5, 7],\n",
    "        'regressor__min_samples_split': [2, 5]\n",
    "    }\n",
    "    best_pipeline = GradientBoostingRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "184855a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Decision Tree':\n",
    "    param_grid = {\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4],\n",
    "        'regressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error']\n",
    "    }\n",
    "    best_pipeline = DecisionTreeRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82219137",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Linear Regression':\n",
    "    print(\"Linear Regression does not require hyperparameter tuning.\")\n",
    "    tuned_r2, tuned_mse, tuned_mae = lr_r2, lr_mse, lr_mae\n",
    "    best_pipeline = lr_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6dfc6148",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model == 'Linear Regression':\n",
    "    print(\"Linear Regression does not require hyperparameter tuning.\")\n",
    "    tuned_r2, tuned_mse, tuned_mae = lr_r2, lr_mse, lr_mae\n",
    "    best_pipeline = lr_pipeline\n",
    "elif best_model == 'Decision Tree':\n",
    "    param_grid = {\n",
    "        'regressor__max_depth': [None, 10, 20, 30],\n",
    "        'regressor__min_samples_split': [2, 5, 10],\n",
    "        'regressor__min_samples_leaf': [1, 2, 4],\n",
    "        'regressor__criterion': ['squared_error', 'friedman_mse', 'absolute_error']\n",
    "    }\n",
    "    best_pipeline = DecisionTreeRegressor()\n",
    "elif best_model == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'regressor__max_depth': [3, 5, 7],\n",
    "        'regressor__min_samples_split': [2, 5]\n",
    "    }\n",
    "    best_pipeline = GradientBoostingRegressor()\n",
    "else:  # SVR\n",
    "    param_grid = {\n",
    "        'regressor__C': [0.1, 1, 10, 100],\n",
    "        'regressor__gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "        'regressor__kernel': ['linear', 'rbf', 'poly']\n",
    "    }\n",
    "    best_pipeline = SVR()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f0f33c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'regressor__C': [0.1, 1, 10, 100],\n",
    "    'regressor__gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'regressor__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0355dac-cb17-4de1-8dc0-59bdfa3fef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1e7d26b7-c9b1-4634-ab9e-9d1c1709b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 10, 20],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fc9548b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Comparison (Before vs. After Tuning):\n",
      "R-squared: 0.9576 -> 0.9591\n",
      "MSE: 3345553.2007 -> 3232388.3535\n",
      "MAE: 1302.0097 -> 1230.7212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Assuming you already have a model (e.g., a RandomForestRegressor or other)\n",
    "# and a parameter grid defined (param_grid)\n",
    "\n",
    "# Example: grid_search initialization and fitting\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the grid search on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model from the grid search results\n",
    "tuned_model = grid_search.best_estimator_\n",
    "\n",
    "# Now evaluate the tuned model using the test set\n",
    "tuned_r2, tuned_mse, tuned_mae = evaluate_model(tuned_model, X_test, y_test)\n",
    "\n",
    "# Now proceed with the performance comparison\n",
    "print(\"\\nModel Performance Comparison (Before vs. After Tuning):\")\n",
    "print(f\"R-squared: {model_comparison.loc[best_model, 'R2']:.4f} -> {tuned_r2:.4f}\")\n",
    "print(f\"MSE: {model_comparison.loc[best_model, 'MSE']:.4f} -> {tuned_mse:.4f}\")\n",
    "print(f\"MAE: {model_comparison.loc[best_model, 'MAE']:.4f} -> {tuned_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "665df0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared Improvement: 0.15%\n"
     ]
    }
   ],
   "source": [
    "improvement_r2 = (tuned_r2 - model_comparison.loc[best_model, 'R2']) / model_comparison.loc[best_model, 'R2'] * 100\n",
    "print(f\"R-squared Improvement: {improvement_r2:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17e248",
   "metadata": {},
   "source": [
    "6. Conclusion\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f51d4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conclusion:\n",
      "1. The best performing model is Random Forest\n",
      "2. Key factors affecting car prices include:\n",
      "   1. enginesize: 0.5479\n",
      "   2. curbweight: 0.2960\n",
      "   3. highwaympg: 0.0452\n",
      "   4. horsepower: 0.0320\n",
      "   5. carwidth: 0.0135\n",
      "3. The model achieves an R-squared of 0.9591 after tuning, explaining 95.91% of the variance in car prices\n",
      "4. The Mean Absolute Error is $1230.72, indicating the average prediction error\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConclusion:\")\n",
    "print(f\"1. The best performing model is {best_model}\")\n",
    "print(\"2. Key factors affecting car prices include:\")\n",
    "if 'fi_df' in locals():\n",
    "    for i, (feature, importance) in enumerate(zip(fi_df['Feature'].head(5), fi_df['Importance'].head(5))):\n",
    "        print(f\"   {i+1}. {feature}: {importance:.4f}\")\n",
    "print(f\"3. The model achieves an R-squared of {tuned_r2:.4f} after tuning, explaining {tuned_r2*100:.2f}% of the variance in car prices\")\n",
    "print(f\"4. The Mean Absolute Error is ${tuned_mae:.2f}, indicating the average prediction error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d6abae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model saved as 'car_price_prediction_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "import joblib\n",
    "joblib.dump(tuned_model if best_model != 'Linear Regression' else best_pipeline, 'car_price_prediction_model.pkl')\n",
    "print(\"\\nFinal model saved as 'car_price_prediction_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55b0aa-d77d-46ba-93ae-bd9df75492e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
